---
title: "Python Scrapy with selenium"
date: 2024-10-10
categories: code-notes
# algorithm-leetcode
# code-notes
# setup-basics
---
<!-- 大綱引言 -->
###### 之前只用過BS4抓過靜態網頁，這次抓 Twitter 看看

<!-- 正文 -->
### Dockerfile

```dockerfile
FROM ubuntu:20.04

# 設置環境變量來避免互動式提示
ENV DEBIAN_FRONTEND=noninteractive

# 更新系統並安裝必要的套件，包括 curl
RUN apt-get update && apt-get install -y \
    firefox \
    wget \
    curl \
    unzip \
    python3 \
    python3-pip \
    tzdata \
    && apt-get clean

# 安裝 geckodriver (適用於 Firefox)
RUN GECKO_VERSION=$(curl -s https://api.github.com/repos/mozilla/geckodriver/releases/latest | grep '"tag_name":' | sed -E 's/.*"([^"]+)".*/\1/') && \
    wget "https://github.com/mozilla/geckodriver/releases/download/$GECKO_VERSION/geckodriver-$GECKO_VERSION-linux64.tar.gz" && \
    tar -xzf geckodriver-$GECKO_VERSION-linux64.tar.gz -C /usr/local/bin && \
    rm geckodriver-$GECKO_VERSION-linux64.tar.gz

# 安裝 Selenium
RUN pip3 install selenium

# 設置環境變量
ENV DISPLAY=:99

# 預設啟動命令，將保持容器運行
CMD ["tail", "-f", "/dev/null"]
```
我的設備是 Mac M1 ，要注意的地方是 geckodriver 部分選擇 firefox 相容性比較好。

### 登入 Twitter 儲存 Cookies
```python
import getpass
import pickle
from selenium import webdriver
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time


class TwitterLoginManager:
    def __init__(self, driver_path: str, cookies_path: str):
        self.driver_path = driver_path
        self.cookies_path = cookies_path
        self.options = Options()
        self.options.add_argument("--headless")
        self.service = Service(driver_path)
        self.driver = None

    def _initialize_driver(self):
        """初始化瀏覽器驅動"""
        self.driver = webdriver.Firefox(
            service=self.service, options=self.options)

    def login_and_save_cookies(self, username: str, password: str) -> bool:
        """登入 Twitter 並保存 cookies"""
        self._initialize_driver()
        try:
            print("正在登入 Twitter...")
            self.driver.get("https://twitter.com/login")

            # 等待登入表單加載
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.NAME, "text"))
            )

            # 輸入使用者名稱
            username_input = self.driver.find_element(By.NAME, "text")
            username_input.send_keys(username)
            username_input.send_keys(u'\ue007')  # 按下 Enter

            # 等待密碼欄位
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.NAME, "password"))
            )

            # 輸入密碼
            password_input = self.driver.find_element(By.NAME, "password")
            password_input.send_keys(password)
            password_input.send_keys(u'\ue007')  # 按下 Enter

            # 等待登入成功並跳轉首頁
            WebDriverWait(self.driver, 10).until(
                EC.url_contains("home")
            )

            # 登入成功，保存 cookies
            with open(self.cookies_path, "wb") as f:
                pickle.dump(self.driver.get_cookies(), f)
            print(f"登入成功，Cookies 已保存到 {self.cookies_path}")

            return True

        except Exception as e:
            print(f"登入失敗: {e}")
            return False

        finally:
            self.driver.quit()

    def verify_cookies(self) -> bool:
        """驗證保存的 cookies 是否有效"""
        self._initialize_driver()
        try:
            print("正在驗證 Cookies...")
            self.driver.get("https://twitter.com")

            # 載入保存的 cookies
            with open(self.cookies_path, "rb") as f:
                cookies = pickle.load(f)
                for cookie in cookies:
                    self.driver.add_cookie(cookie)

            # 嘗試進入首頁，確認是否保持登入狀態
            self.driver.get("https://twitter.com/home")
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "title"))
            )

            print(f"已使用 Cookies 保持登入狀態，當前頁面標題: {self.driver.title}")
            return True

        except Exception as e:
            print(f"驗證失敗: {e}")
            return False

        finally:
            self.driver.quit()


if __name__ == "__main__":
    driver_path = "/usr/local/bin/geckodriver"
    cookies_path = "twitter_cookies.pkl"

    twitter_manager = TwitterLoginManager(driver_path, cookies_path)

    # 提示使用者輸入 Twitter 帳號和密碼
    username = input("請輸入您的 Twitter 使用者名稱: ")
    password = getpass.getpass("請輸入您的 Twitter 密碼: ")  # 使用 getpass 隱藏密碼輸入

    # 登入並儲存 Cookies
    if twitter_manager.login_and_save_cookies(username, password):
        # 驗證 Cookies 是否有效
        twitter_manager.verify_cookies()

```
成功登入後儲存 cookies 資訊到新建的 `twitter_cookies.pkl`，並再次測試儲存的 cookies 功能性。

### 抓取資訊
```python
import time
from selenium.webdriver.common.action_chains import ActionChains
import pickle
from selenium import webdriver
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

# 設置 Firefox 瀏覽器的無頭模式（不顯示界面）
options = Options()
options.add_argument("--headless")
service = Service("/usr/local/bin/geckodriver")
driver = webdriver.Firefox(service=service, options=options)

# 儲存抓取的推文內容檔案
output_file = "output.txt"

# 讀取已儲存的推文檔案，取得最新的推文資訊


def load_existing_articles(filename):
    try:
        with open(filename, "r", encoding="utf-8") as file:
            content = file.readlines()
        # 提取最新的一篇推文資訊
        return content[-1].strip() if content else None
    except FileNotFoundError:
        return None  # 如果檔案不存在，返回 None

# 儲存抓取結果至檔案，將新推文添加到檔案的最前面


def save_to_file(filename, content_list):
    try:
        with open(filename, "r", encoding="utf-8") as file:
            existing_content = file.readlines()
    except FileNotFoundError:
        existing_content = []

    # 把新抓取的推文內容加到最前面，然後再寫回檔案
    with open(filename, "w", encoding="utf-8") as file:
        # 先寫入新抓取的內容
        file.write("\n".join(content_list) + "\n")
        # 再寫入之前的內容
        file.writelines(existing_content)
    print(f"抓取結果已儲存至 {filename}")


# 初始化推文集合和抓取列表
fetched_articles = set()
articles_list = []

# 讀取檔案中最新的一條推文，用於重複檢查
last_article = load_existing_articles(output_file)
repeated_count = 0  # 記錄重複抓取次數
max_repeated = 5  # 連續抓取到 5 次重複則停止

try:
    # 打開 Twitter 頁面
    driver.get("https://twitter.com")

    # 載入之前保存的 cookies
    with open("twitter_cookies.pkl", "rb") as f:
        cookies = pickle.load(f)
        for cookie in cookies:
            driver.add_cookie(cookie)

    # 打開指定 Twitter 頁面
    driver.get("https://x.com/eninaranaiotoko")
    actions = ActionChains(driver)
    time.sleep(5)  # 等待頁面完全加載

    # 定義一個用來抓取文章的函數
    def get_articles():
        global repeated_count
        articles = driver.find_elements(By.XPATH, "//article")
        for idx, article in enumerate(articles, start=1):
            try:
                # 抓取文章的時間作為唯一標識
                time_element = article.find_element(
                    By.XPATH, ".//time").get_attribute("datetime")
                text_element = article.text[:10]  # 文章的前 10 個字元

                # 組合推文資訊
                article_info = f"{len(fetched_articles)+1}篇推文 // {time_element} // {text_element}"

                # 檢查文章是否已經抓取過
                if time_element not in fetched_articles:
                    if article_info == last_article:
                        repeated_count += 1
                        print(f"重複第 {repeated_count} 次: {article_info}")
                        if repeated_count >= max_repeated:
                            print("連續抓取到重複推文，停止抓取。")
                            return False  # 停止抓取
                    else:
                        repeated_count = 0  # 重置計數器
                        fetched_articles.add(time_element)
                        articles_list.append(article_info)
                        print(article_info)
            except Exception as e:
                print(f"抓取文章失敗: {e}")
        return True  # 繼續抓取

    # 模擬多次按下空白鍵，每次都抓取可見的文章
    for i in range(30):  # 模擬按下空白鍵 30 次
        print(f"\n--- 第 {i+1} 次抓取 ---")
        if not get_articles():  # 如果抓取到重複推文，結束
            break

        # 模擬按住空白鍵 0.3 秒後放開
        actions.key_down(Keys.SPACE).perform()
        time.sleep(0.3)  # 按住 0.3 秒
        actions.key_up(Keys.SPACE).perform()
        time.sleep(2)  # 等待頁面內容加載

except Exception as e:
    print(f"頁面加載失敗: {e}")

finally:
    # 關閉瀏覽器
    driver.quit()
    # 儲存抓取的推文
    if articles_list:
        save_to_file(output_file, articles_list)
    else:
        print("沒有新推文被抓取。")

```
觀察 twitter dom 和如何賦予 <tag calss>，我觀察到文章方塊&網頁高度是這兩個

```html
### twitter main post block
/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/section/div

### twitter control height
/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/section/div/div
```

### 總結
1. 只是要獲取資訊的話，有API先用API
2. 找到某個重複的規律
3. 目前效率不好但功能可以執行
